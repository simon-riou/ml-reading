@article{muller2019smoothinglabel,
  title        = {When Does Label Smoothing Help?},
  author       = {Müller, Rafael and Kornblith, Simon and Hinton, Geoffrey},
  journal      = {arXiv preprint arXiv:1906.02629},
  year         = {2019},
  url          = {https://arxiv.org/abs/1906.02629},
  note         = {Accepted at NeurIPS 2019}
}
@article{G.muller2021trivialaugment,
  title        = {TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation},
  author       = {Samuel G. Müller, Frank Hutter},
  journal      = {arXiv preprint arXiv:2103.10158},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.10158},
  note         = {Accepted at ICCV 2021 as Ora}
}
@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@article{vryniotis2021trainsatoclassifiermodels,
  title        = {How to Train State-Of-The-Art Models Using TorchVision’s Latest Primitives"},
  author       = {Vasilis Vryniotis},
  journal      = {Pytorch Blog},
  year         = {2021},
  url          = {https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#label-smoothing},
  note         = {}
}
@article{dosovitskiy2021ViT,
  title        = {AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE"},
  author       = {Alexey Dosovitskiy},
  journal      = {ICLR 2021},
  year         = {2021},
  url          = {https://arxiv.org/abs/2010.11929},
  note         = {}
}
@article{he2015deep,
    title={Deep Residual Learning for Image Recognition},
    author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    year={2015},
    url={https://arxiv.org/abs/1512.03385},
    eprint={1512.03385},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
@article{ioffe2015batchnormalizationacceleratingdeep,
      title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}, 
      author={Sergey Ioffe and Christian Szegedy},
      year={2015},
      eprint={1502.03167},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1502.03167}, 
}
@article{simonyan2015deepconvolutionalnetworkslargescale,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1409.1556}, 
}
@article{geiping2022crammingtraininglanguagemodel,
      title={Cramming: Training a Language Model on a Single GPU in One Day}, 
      author={Jonas Geiping and Tom Goldstein},
      year={2022},
      eprint={2212.14034},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.14034}, 
}
@article{ho2020denoisingdiffusionprobabilisticmodels,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.11239}, 
}